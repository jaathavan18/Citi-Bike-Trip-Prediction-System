{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803a32dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class BaselineModelPreviousHour:\n",
    "    \"\"\"\n",
    "    A simple baseline model that uses the previous time step's value (e.g., rides_t-1)\n",
    "    as the prediction for the current time step.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series):\n",
    "        # No training needed for baseline model\n",
    "        pass\n",
    "\n",
    "    def predict(self, X_test: pd.DataFrame) -> np.ndarray:\n",
    "        if \"target_lag_1\" not in X_test.columns:\n",
    "            raise ValueError(\"X_test must contain 'target_lag_1' column.\")\n",
    "        return X_test[\"target_lag_1\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d1566b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä BaselineModelPreviousHour Evaluation:\n",
      "‚û°Ô∏è MAE:  103.48\n",
      "‚û°Ô∏è MAPE: 485.11%\n",
      "‚û°Ô∏è RMSE: 115.55\n",
      "‚û°Ô∏è R¬≤:   -0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load transformed data\n",
    "df = pd.read_parquet(\"transformeddata2024.parquet\")\n",
    "\n",
    "# Define features and target\n",
    "features = [col for col in df.columns if col not in ['pickup_hour', 'target', 'location_id']]\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# Simulate train/test split (use last 20% as test)\n",
    "split_idx = int(0.8 * len(df))\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "# Baseline model\n",
    "baseline = BaselineModelPreviousHour()\n",
    "baseline.fit(X_train, y_train)\n",
    "y_pred = baseline.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "print(\"üìä BaselineModelPreviousHour Evaluation:\")\n",
    "print(f\"‚û°Ô∏è MAE:  {mae:.2f}\")\n",
    "print(f\"‚û°Ô∏è MAPE: {mape:.2f}%\")\n",
    "print(f\"‚û°Ô∏è RMSE: {rmse:.2f}\")\n",
    "print(f\"‚û°Ô∏è R¬≤:   {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abdd71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def set_mlflow_tracking():\n",
    "    \"\"\"\n",
    "    Set up MLflow tracking server credentials and URI.\n",
    "    \"\"\"\n",
    "    uri = os.environ[\"MLFLOW_TRACKING_URI\"]\n",
    "    print(uri)\n",
    "    mlflow.set_tracking_uri(uri)\n",
    "    logger.info(\"MLflow tracking URI and credentials set.\")\n",
    "\n",
    "    return mlflow\n",
    "\n",
    "\n",
    "def log_model_to_mlflow(\n",
    "     model,\n",
    "    input_data,\n",
    "    experiment_name,\n",
    "    metric_name=\"metric\",\n",
    "    model_name=None,\n",
    "    params=None,\n",
    "    mae=None,\n",
    "    mape=None,\n",
    "    rmse=None,\n",
    "    r2=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Log a trained model, parameters, and metrics to MLflow.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model object (e.g., sklearn model).\n",
    "    - input_data: Input data used for training (for signature inference).\n",
    "    - experiment_name: Name of the MLflow experiment.\n",
    "    - metric_name: Name of the metric to log (e.g., \"RMSE\", \"accuracy\").\n",
    "    - model_name: Optional name for the registered model.\n",
    "    - params: Optional dictionary of hyperparameters to log.\n",
    "    - score: Optional evaluation metric to log.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set the experiment\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        logger.info(f\"Experiment set to: {experiment_name}\")\n",
    "\n",
    "        # Start an MLflow run\n",
    "        with mlflow.start_run():\n",
    "            # Log hyperparameters if provided\n",
    "            if params:\n",
    "                mlflow.log_params(params)\n",
    "                logger.info(f\"Logged parameters: {params}\")\n",
    "\n",
    "            # Log metrics if provided\n",
    "            if mae is not None:\n",
    "                mlflow.log_metric(metric_name, mae)\n",
    "                mlflow.log_metric(\"mape\", mape)\n",
    "                mlflow.log_metric(\"rmse\", rmse)\n",
    "                mlflow.log_metric(\"r2\", r2)\n",
    "                logger.info(f\"Logged {metric_name}: {mae}\")\n",
    "\n",
    "            # Infer the model signature\n",
    "            signature = infer_signature(input_data, model.predict(input_data))\n",
    "            logger.info(\"Model signature inferred.\")\n",
    "\n",
    "            # Determine the model name\n",
    "            if not model_name:\n",
    "                model_name = model.__class__.__name__\n",
    "\n",
    "            # Log the model\n",
    "            model_info = mlflow.sklearn.log_model(\n",
    "                sk_model=model,\n",
    "                artifact_path=\"model_artifact\",\n",
    "                signature=signature,\n",
    "                input_example=input_data,\n",
    "                registered_model_name=model_name,\n",
    "            )\n",
    "            logger.info(f\"Model logged with name: {model_name}\")\n",
    "            return model_info\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while logging to MLflow: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe9b9d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dagshub.com/jaathavan18/citi_bike_pred.mlflow\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "uri = os.environ[\"MLFLOW_TRACKING_URI\"]\n",
    "print(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f677ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:MLflow tracking URI and credentials set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dagshub.com/jaathavan18/citi_bike_pred.mlflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/11 11:56:56 INFO mlflow.tracking.fluent: Experiment with name 'BaselineModel' does not exist. Creating a new experiment.\n",
      "INFO:__main__:Experiment set to: BaselineModel\n",
      "INFO:__main__:Logged mean_absolute_error: 103.47672955974842\n",
      "c:\\Users\\Jaath\\anaconda3\\envs\\citienv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "INFO:__main__:Model signature inferred.\n",
      "c:\\Users\\Jaath\\anaconda3\\envs\\citienv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 1984.87it/s]\n",
      "2025/05/11 11:57:02 INFO mlflow.models.model: Found the following environment variables used during model inference: [HOPSWORKS_API_KEY]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "Registered model 'BaselineModelPreviousHour' already exists. Creating a new version of this model...\n",
      "2025/05/11 11:57:08 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: BaselineModelPreviousHour, version 2\n",
      "Created version '2' of model 'BaselineModelPreviousHour'.\n",
      "INFO:__main__:Model logged with name: BaselineModelPreviousHour\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run inquisitive-slug-926 at: https://dagshub.com/jaathavan18/citi_bike_pred.mlflow/#/experiments/11/runs/bc88da64c80c43398fed2a33694958fe\n",
      "üß™ View experiment at: https://dagshub.com/jaathavan18/citi_bike_pred.mlflow/#/experiments/11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x19f116ac810>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "mlflow = set_mlflow_tracking()\n",
    "log_model_to_mlflow(model=baseline,\n",
    "    input_data=X_test,\n",
    "    experiment_name=\"BaselineModel\",\n",
    "    metric_name=\"mean_absolute_error\",\n",
    "    mae=mae,      \n",
    "    mape=mape,\n",
    "    rmse=rmse,\n",
    "    r2=r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
