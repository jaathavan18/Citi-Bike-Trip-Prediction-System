{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25afeaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Column dtypes before preprocessing:\n",
      "pickup_hour       datetime64[ns]\n",
      "location_id               object\n",
      "target                     int64\n",
      "target_lag_1             float64\n",
      "target_lag_2             float64\n",
      "                       ...      \n",
      "target_lag_112           float64\n",
      "hour                       int32\n",
      "day_of_week                int32\n",
      "month                      int32\n",
      "is_weekend                 int32\n",
      "Length: 119, dtype: object\n",
      "‚ö†Ô∏è Found datetime columns: ['pickup_hour']\n",
      "\n",
      "üîç Column dtypes after preprocessing:\n",
      "target_lag_1               float64\n",
      "target_lag_2               float64\n",
      "target_lag_3               float64\n",
      "target_lag_4               float64\n",
      "target_lag_5               float64\n",
      "                            ...   \n",
      "is_weekend                   int32\n",
      "pickup_hour_hour             int32\n",
      "pickup_hour_day_of_week      int32\n",
      "pickup_hour_month            int32\n",
      "pickup_hour_is_weekend       int32\n",
      "Length: 120, dtype: object\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28605\n",
      "[LightGBM] [Info] Number of data points in the train set: 3154, number of used features: 120\n",
      "[LightGBM] [Info] Start training from score 106.961953\n",
      "\n",
      "üèÜ Top 10 Feature Importances:\n",
      "           feature  importance\n",
      "0     target_lag_1         187\n",
      "3     target_lag_4         126\n",
      "1     target_lag_2          89\n",
      "113    day_of_week          72\n",
      "6     target_lag_7          55\n",
      "27   target_lag_28          55\n",
      "112           hour          48\n",
      "2     target_lag_3          47\n",
      "4     target_lag_5          46\n",
      "55   target_lag_56          45\n",
      "\n",
      "üåü PCA Results:\n",
      "Number of components selected: 7\n",
      "Explained variance ratio: 0.9537\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1785\n",
      "[LightGBM] [Info] Number of data points in the train set: 3154, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 106.961953\n",
      "\n",
      "üìä LightGBM Model Evaluation (Top 10 Features + PCA):\n",
      "‚û°Ô∏è MAE:  23.14\n",
      "‚û°Ô∏è MAPE: 74.35%\n",
      "‚û°Ô∏è RMSE: 35.89\n",
      "‚û°Ô∏è R¬≤:   0.81\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2049\n",
      "[LightGBM] [Info] Number of data points in the train set: 3154, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 106.961953\n",
      "\n",
      "üìä LightGBM Model Evaluation (Top 10 Features, No PCA):\n",
      "‚û°Ô∏è MAE:  21.53\n",
      "‚û°Ô∏è MAPE: 62.12%\n",
      "‚û°Ô∏è RMSE: 33.99\n",
      "‚û°Ô∏è R¬≤:   0.83\n",
      "\n",
      "üì¶ Models and preprocessing objects saved.\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LightGBMRegressorModel:\n",
    "    \"\"\"\n",
    "    A wrapper around LightGBM Regressor for consistent interface.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = lgb.LGBMRegressor(random_state=42, **kwargs)\n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series):\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test: pd.DataFrame) -> np.ndarray:\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def feature_importance(self, feature_names: list) -> pd.DataFrame:\n",
    "        return pd.DataFrame({\n",
    "            \"feature\": feature_names,\n",
    "            \"importance\": self.model.feature_importances_\n",
    "        }).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / np.where(y_true != 0, y_true, 1))) * 100  # Avoid division by zero\n",
    "    return {\"MAE\": mae, \"MAPE\": mape, \"RMSE\": rmse, \"R¬≤\": r2}\n",
    "\n",
    "# Function to preprocess datetime columns\n",
    "def preprocess_datetime_columns(df, columns):\n",
    "    \"\"\"\n",
    "    Convert datetime columns to numerical features (hour, day_of_week, month, etc.).\n",
    "    Returns a new DataFrame with transformed columns.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    for col in columns:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[f\"{col}_hour\"] = df_copy[col].dt.hour\n",
    "            df_copy[f\"{col}_day_of_week\"] = df_copy[col].dt.dayofweek\n",
    "            df_copy[f\"{col}_month\"] = df_copy[col].dt.month\n",
    "            df_copy[f\"{col}_is_weekend\"] = df_copy[col].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "            df_copy = df_copy.drop(columns=[col])  # Drop original datetime column\n",
    "    return df_copy\n",
    "\n",
    "# Load transformed data\n",
    "df = pd.read_parquet(\"../transformeddata2024.parquet\")\n",
    "\n",
    "# Debug: Inspect column dtypes\n",
    "print(\"üîç Column dtypes before preprocessing:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Define features and target\n",
    "exclude_cols = ['Pickup_hour', 'target', 'location_id']\n",
    "features = [col for col in df.columns if col not in exclude_cols]\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# Identify datetime columns\n",
    "datetime_cols = X.select_dtypes(include=['datetime64', 'datetime64[ns]', 'datetime64[ns, UTC]']).columns.tolist()\n",
    "if datetime_cols:\n",
    "    print(f\"‚ö†Ô∏è Found datetime columns: {datetime_cols}\")\n",
    "    X = preprocess_datetime_columns(X, datetime_cols)\n",
    "    features = [col for col in X.columns]  # Update feature list after preprocessing\n",
    "else:\n",
    "    print(\"‚úÖ No datetime columns found.\")\n",
    "\n",
    "# Debug: Verify dtypes after preprocessing\n",
    "print(\"\\nüîç Column dtypes after preprocessing:\")\n",
    "print(X.dtypes)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 1: Train initial LightGBM model to get feature importance\n",
    "initial_model = LightGBMRegressorModel()\n",
    "initial_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance and select top 10 features\n",
    "feature_importance = initial_model.feature_importance(features)\n",
    "top_10_features = feature_importance.head(10)[\"feature\"].tolist()\n",
    "\n",
    "print(\"\\nüèÜ Top 10 Feature Importances:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Step 2: Filter data to top 10 features\n",
    "X_train_top10 = X_train[top_10_features]\n",
    "X_test_top10 = X_test[top_10_features]\n",
    "\n",
    "# Step 3: Standardize data for PCA\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_top10)\n",
    "X_test_scaled = scaler.transform(X_test_top10)\n",
    "\n",
    "# Step 4: Apply PCA (retain 95% of variance)\n",
    "pca = PCA(n_components=0.95)  # Keep components explaining 95% of variance\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"\\nüåü PCA Results:\")\n",
    "print(f\"Number of components selected: {pca.n_components_}\")\n",
    "print(f\"Explained variance ratio: {np.sum(pca.explained_variance_ratio_):.4f}\")\n",
    "\n",
    "# Step 5: Train LightGBM model on PCA-transformed data\n",
    "pca_model = LightGBMRegressorModel()\n",
    "pca_model.fit(X_train_pca, y_train)\n",
    "y_pred_pca = pca_model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate PCA model\n",
    "pca_metrics = evaluate_model(y_test, y_pred_pca)\n",
    "\n",
    "print(\"\\nüìä LightGBM Model Evaluation (Top 10 Features + PCA):\")\n",
    "print(f\"‚û°Ô∏è MAE:  {pca_metrics['MAE']:.2f}\")\n",
    "print(f\"‚û°Ô∏è MAPE: {pca_metrics['MAPE']:.2f}%\")\n",
    "print(f\"‚û°Ô∏è RMSE: {pca_metrics['RMSE']:.2f}\")\n",
    "print(f\"‚û°Ô∏è R¬≤:   {pca_metrics['R¬≤']:.2f}\")\n",
    "\n",
    "# Optional: Train and evaluate model on top 10 features without PCA for comparison\n",
    "top10_model = LightGBMRegressorModel()\n",
    "top10_model.fit(X_train_top10, y_train)\n",
    "y_pred_top10 = top10_model.predict(X_test_top10)\n",
    "top10_metrics = evaluate_model(y_test, y_pred_top10)\n",
    "\n",
    "print(\"\\nüìä LightGBM Model Evaluation (Top 10 Features, No PCA):\")\n",
    "print(f\"‚û°Ô∏è MAE:  {top10_metrics['MAE']:.2f}\")\n",
    "print(f\"‚û°Ô∏è MAPE: {top10_metrics['MAPE']:.2f}%\")\n",
    "print(f\"‚û°Ô∏è RMSE: {top10_metrics['RMSE']:.2f}\")\n",
    "print(f\"‚û°Ô∏è R¬≤:   {top10_metrics['R¬≤']:.2f}\")\n",
    "\n",
    "# Save the models and preprocessing objects (optional)\n",
    "import joblib\n",
    "joblib.dump(pca_model.model, \"lightgbm_pca_model.joblib\")\n",
    "joblib.dump(top10_model.model, \"lightgbm_top10_model.joblib\")\n",
    "joblib.dump(scaler, \"scaler.joblib\")\n",
    "joblib.dump(pca, \"pca.joblib\")\n",
    "print(\"\\nüì¶ Models and preprocessing objects saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad0a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def set_mlflow_tracking():\n",
    "    \"\"\"\n",
    "    Set up MLflow tracking server credentials and URI.\n",
    "    \"\"\"\n",
    "    uri = os.environ[\"MLFLOW_TRACKING_URI\"]\n",
    "    print(uri)\n",
    "    mlflow.set_tracking_uri(uri)\n",
    "    logger.info(\"MLflow tracking URI and credentials set.\")\n",
    "\n",
    "    return mlflow\n",
    "\n",
    "\n",
    "def log_model_to_mlflow(\n",
    "     model,\n",
    "    input_data,\n",
    "    experiment_name,\n",
    "    metric_name=\"metric\",\n",
    "    model_name=None,\n",
    "    params=None,\n",
    "    mae=None,\n",
    "    mape=None,\n",
    "    rmse=None,\n",
    "    r2=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Log a trained model, parameters, and metrics to MLflow.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model object (e.g., sklearn model).\n",
    "    - input_data: Input data used for training (for signature inference).\n",
    "    - experiment_name: Name of the MLflow experiment.\n",
    "    - metric_name: Name of the metric to log (e.g., \"RMSE\", \"accuracy\").\n",
    "    - model_name: Optional name for the registered model.\n",
    "    - params: Optional dictionary of hyperparameters to log.\n",
    "    - score: Optional evaluation metric to log.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set the experiment\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        logger.info(f\"Experiment set to: {experiment_name}\")\n",
    "\n",
    "        # Start an MLflow run\n",
    "        with mlflow.start_run():\n",
    "            # Log hyperparameters if provided\n",
    "            if params:\n",
    "                mlflow.log_params(params)\n",
    "                logger.info(f\"Logged parameters: {params}\")\n",
    "\n",
    "            # Log metrics if provided\n",
    "            if mae is not None:\n",
    "                mlflow.log_metric(metric_name, mae)\n",
    "                mlflow.log_metric(\"mape\", mape)\n",
    "                mlflow.log_metric(\"rmse\", rmse)\n",
    "                mlflow.log_metric(\"r2\", r2)\n",
    "                logger.info(f\"Logged {metric_name}: {mae}\")\n",
    "\n",
    "            # Infer the model signature\n",
    "            signature = infer_signature(input_data, model.predict(input_data))\n",
    "            logger.info(\"Model signature inferred.\")\n",
    "\n",
    "            # Determine the model name\n",
    "            if not model_name:\n",
    "                model_name = model.__class__.__name__\n",
    "\n",
    "            # Log the model\n",
    "            model_info = mlflow.sklearn.log_model(\n",
    "                sk_model=model,\n",
    "                artifact_path=\"model_artifact\",\n",
    "                signature=signature,\n",
    "                input_example=input_data,\n",
    "                registered_model_name=model_name,\n",
    "            )\n",
    "            logger.info(f\"Model logged with name: {model_name}\")\n",
    "            return model_info\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while logging to MLflow: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9895ed3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:MLflow tracking URI and credentials set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dagshub.com/jaathavan18/citi_bike_pred.mlflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/11 13:14:42 INFO mlflow.tracking.fluent: Experiment with name 'LightGbmModelWithOutPCA' does not exist. Creating a new experiment.\n",
      "INFO:__main__:Experiment set to: LightGbmModelWithOutPCA\n",
      "INFO:__main__:Logged mean_absolute_error: 21.528011210702736\n",
      "c:\\Users\\Jaath\\anaconda3\\envs\\citienv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "INFO:__main__:Model signature inferred.\n",
      "c:\\Users\\Jaath\\anaconda3\\envs\\citienv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 1683.30it/s]\n",
      "2025/05/11 13:14:49 INFO mlflow.models.model: Found the following environment variables used during model inference: [HOPSWORKS_API_KEY]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "Registered model 'LightGBMRegressorModel' already exists. Creating a new version of this model...\n",
      "2025/05/11 13:14:55 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LightGBMRegressorModel, version 2\n",
      "Created version '2' of model 'LightGBMRegressorModel'.\n",
      "INFO:__main__:Model logged with name: LightGBMRegressorModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run gifted-whale-368 at: https://dagshub.com/jaathavan18/citi_bike_pred.mlflow/#/experiments/12/runs/285a702f1a164a9c9d682ce2c51f584d\n",
      "üß™ View experiment at: https://dagshub.com/jaathavan18/citi_bike_pred.mlflow/#/experiments/12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x21779d5c490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "mlflow = set_mlflow_tracking()\n",
    "log_model_to_mlflow(model=top10_model,\n",
    "    input_data=X_test_top10,\n",
    "    experiment_name=\"LightGbmModelWithOutPCA\",\n",
    "    metric_name=\"mean_absolute_error\",\n",
    "    mae=top10_metrics['MAE'],      \n",
    "    mape=top10_metrics['MAPE'],\n",
    "    rmse=top10_metrics['RMSE'],\n",
    "    r2=top10_metrics['R¬≤'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27316643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:MLflow tracking URI and credentials set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dagshub.com/jaathavan18/citi_bike_pred.mlflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Experiment set to: LightGbmModelWithOutPCA\n",
      "INFO:__main__:Logged mean_absolute_error: 23.142474214359762\n",
      "INFO:__main__:Model signature inferred.\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 1750.34it/s]\n",
      "Registered model 'LightGBMRegressorModel' already exists. Creating a new version of this model...\n",
      "2025/05/11 13:15:12 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LightGBMRegressorModel, version 3\n",
      "Created version '3' of model 'LightGBMRegressorModel'.\n",
      "INFO:__main__:Model logged with name: LightGBMRegressorModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run merciful-stork-350 at: https://dagshub.com/jaathavan18/citi_bike_pred.mlflow/#/experiments/12/runs/cec0b27508b540389947b1fad1cae1ab\n",
      "üß™ View experiment at: https://dagshub.com/jaathavan18/citi_bike_pred.mlflow/#/experiments/12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x217028a0b10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "mlflow = set_mlflow_tracking()\n",
    "log_model_to_mlflow(model=pca_model,\n",
    "    input_data=X_test_pca,\n",
    "    experiment_name=\"LightGbmModelWithOutPCA\",\n",
    "    metric_name=\"mean_absolute_error\",\n",
    "    mae=pca_metrics['MAE'],      \n",
    "    mape=pca_metrics['MAPE'],\n",
    "    rmse=pca_metrics['RMSE'],\n",
    "    r2=pca_metrics['R¬≤'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
