{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45204c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-11 12:08:27,818 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-11 12:08:27,822 INFO: Initializing external client\n",
      "2025-05-11 12:08:27,822 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-11 12:08:28,657 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1228972\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import config as config\n",
    "from pathlib import Path\n",
    "import hopsworks\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "project = hopsworks.login(\n",
    "    project=os.getenv(\"HOPSWORKS_PROJECT_NAME\"),\n",
    "    api_key_value=os.getenv(\"HOPSWORKS_API_KEY\")\n",
    ")\n",
    "feature_store = project.get_feature_store()\n",
    "feature_group=feature_store.get_or_create_feature_group(\n",
    "    name=os.getenv(\"FEATURE_GROUP_NAME\"),\n",
    "    version=os.getenv(\"FEATURE_GROUP_VERSION\"),\n",
    "    description= \"Time-series Data for Bike at six hour frequency\",\n",
    "    primary_key=[\"location_id\",\"pickup_hour\"],\n",
    "    event_time=\"pickup_hour\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70aca53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating feature view: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1228972/featurestores/1213539/featureview). Server response: \n",
      "HTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":270179,\"usrMsg\":\"Feature view: time_series_six_hourly_feature_view_bike, version: 1\",\"errorMsg\":\"The provided feature view name and version already exists\"}', error code: 270179, error msg: The provided feature view name and version already exists, user msg: Feature view: time_series_six_hourly_feature_view_bike, version: 1\n",
      "Feature view 'time_series_six_hourly_feature_view_bike' (version 1) retrieved successfully.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Create a feature view if it doesn't already exist\n",
    "try:\n",
    "    feature_store.create_feature_view(\n",
    "        name=os.getenv('FEATURE_VIEW_NAME'),\n",
    "        version=os.getenv('FEATURE_VIEW_VERSION'),\n",
    "        query=feature_group.select_all(),\n",
    "    )\n",
    "    print(f\"Feature view '{os.getenv('FEATURE_VIEW_NAME')}' (version {os.getenv('FEATURE_VIEW_VERSION')}) created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating feature view: {e}\")\n",
    "\n",
    "# Retrieve the feature view\n",
    "try:\n",
    "    feature_view = feature_store.get_feature_view(\n",
    "        name=os.getenv('FEATURE_VIEW_NAME'),\n",
    "        version=os.getenv('FEATURE_VIEW_VERSION'),\n",
    "    )\n",
    "    print(f\"Feature view '{os.getenv('FEATURE_VIEW_NAME')}' (version {os.getenv('FEATURE_VIEW_VERSION')}) retrieved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving feature view: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f22f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-11 12:08:33,266 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-11 12:08:33,269 INFO: Initializing external client\n",
      "2025-05-11 12:08:33,271 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-11 12:08:34,344 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1228972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 279868/279868 elapsed<00:00 remaining<00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... DONE\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "def get_hopsworks_project() -> hopsworks.project.Project:\n",
    "    return hopsworks.login(\n",
    "        project=os.getenv('HOPSWORKS_PROJECT_NAME'), api_key_value=os.getenv('HOPSWORKS_API_KEY')\n",
    "    )\n",
    "project = get_hopsworks_project()\n",
    "model_registry = project.get_model_registry()\n",
    "\n",
    "models = model_registry.get_models(name='Bike_demand_predictor_next_hour')\n",
    "model = max(models, key=lambda model: model.version)\n",
    "model_dir = model.download()\n",
    "model = joblib.load(Path(model_dir) / \"lightgbm_bikeride_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "068a3e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.26s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `5`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Generating predictions for 2025...\n",
      "‚úÖ 2025 predictions complete.\n",
      "üìÅ Saved as bike_predictions_2025_6hr.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load feature view data from Hopsworks\n",
    "ts_data, _ = feature_view.training_data(\n",
    "    description=\"time_series_six_hourly_bike_ride\"\n",
    ")\n",
    "\n",
    "# Step 2: Preprocess location_id\n",
    "ts_data[\"location_id\"] = ts_data[\"location_id\"].astype(str).str.replace('.', '', regex=False)\n",
    "ts_data[\"pickup_hour\"] = pd.to_datetime(ts_data[\"pickup_hour\"])\n",
    "\n",
    "# Keep only the 3 exact stations\n",
    "valid_ids = {\"614005\", \"590514\", \"532903\"}\n",
    "ts_data = ts_data[ts_data[\"location_id\"].isin(valid_ids)]\n",
    "\n",
    "# Step 3: Setup for prediction\n",
    "full_df = ts_data.copy()\n",
    "predictions = []\n",
    "\n",
    "# Define prediction timeline and cleaned location IDs\n",
    "future_dates = pd.date_range(\"2025-01-01 00:00:00\", \"2025-12-31 18:00:00\", freq=\"6H\", tz=\"UTC\")\n",
    "location_ids = sorted(valid_ids)  # keep it ordered\n",
    "\n",
    "# Step 4: LightGBM expects these exact features\n",
    "reg_features = [f\"target_lag_{i+1}\" for i in range(112)] + [\"hour\", \"day_of_week\", \"month\", \"is_weekend\", \"location_id\"]\n",
    "\n",
    "print(\"üîÆ Generating predictions for 2025...\")\n",
    "\n",
    "# Step 5: Rolling prediction loop\n",
    "for ts in future_dates:\n",
    "    for loc in location_ids:\n",
    "        # Get latest 112 lag entries for this station\n",
    "        hist = full_df[full_df[\"location_id\"] == loc].sort_values(\"pickup_hour\").tail(112)\n",
    "        if len(hist) < 112:\n",
    "            continue\n",
    "\n",
    "        # Create lag features\n",
    "        feature_row = {\n",
    "            f\"target_lag_{i+1}\": hist.iloc[-(i+1)][\"target\"] for i in range(112)\n",
    "        }\n",
    "\n",
    "        # Add time-based features\n",
    "        feature_row[\"hour\"] = ts.hour\n",
    "        feature_row[\"day_of_week\"] = ts.dayofweek\n",
    "        feature_row[\"month\"] = ts.month\n",
    "        feature_row[\"is_weekend\"] = int(ts.dayofweek in [5, 6])\n",
    "        feature_row[\"pickup_hour\"] = ts\n",
    "        feature_row[\"location_id\"] = loc\n",
    "\n",
    "        # Prepare DataFrame for prediction\n",
    "        X_pred = pd.DataFrame([feature_row])[reg_features]\n",
    "        X_pred[\"location_id\"] = X_pred[\"location_id\"].astype(float)  # ensure numeric for LGBM\n",
    "\n",
    "        # Predict\n",
    "        pred = model.predict(X_pred)[0]\n",
    "\n",
    "        # Store prediction\n",
    "        predictions.append({\n",
    "            \"pickup_hour\": ts,\n",
    "            \"location_id\": loc,\n",
    "            \"predicted_rides\": round(pred)\n",
    "        })\n",
    "\n",
    "        # Append predicted row to history for future lags\n",
    "        full_df = pd.concat([\n",
    "            full_df,\n",
    "            pd.DataFrame([{\n",
    "                **feature_row,\n",
    "                \"target\": pred\n",
    "            }])\n",
    "        ], ignore_index=True)\n",
    "\n",
    "print(\"‚úÖ 2025 predictions complete.\")\n",
    "\n",
    "# Step 6: Save predictions\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.to_csv(\"bike_predictions_2025_6hr.csv\", index=False)\n",
    "print(\"üìÅ Saved as bike_predictions_2025_6hr.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03ead1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1228972/fs/1213539/fg/1454690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 4380/4380 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: bike_demand_predictions_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1228972/jobs/named/bike_demand_predictions_1_offline_fg_materialization/executions\n",
      "2025-05-11 12:12:05,178 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-05-11 12:13:15,268 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-05-11 12:14:44,253 INFO: Waiting for execution to finish. Current state: SUCCEEDING. Final status: UNDEFINED\n",
      "2025-05-11 12:14:47,352 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-05-11 12:14:47,440 INFO: Waiting for log aggregation to finish.\n",
      "2025-05-11 12:14:59,597 INFO: Execution finished successfully.\n",
      "‚úÖ Predictions uploaded to Hopsworks Feature Group: bike_demand_predictions v1\n"
     ]
    }
   ],
   "source": [
    "# Get Hopsworks feature store\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# Create a new feature group\n",
    "fg_pred = fs.create_feature_group(\n",
    "    name=\"bike_demand_predictions\",\n",
    "    version=1,\n",
    "    description=\"6-hourly predicted demand for 2025\",\n",
    "    primary_key=[\"pickup_hour\", \"location_id\"],\n",
    "    event_time=\"pickup_hour\"\n",
    ")\n",
    "\n",
    "# Save data to the new feature group\n",
    "fg_pred.insert(pred_df, write_options={\"wait_for_job\": True})\n",
    "print(\"‚úÖ Predictions uploaded to Hopsworks Feature Group: bike_demand_predictions v1\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
