{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c708dd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28586\n",
      "[LightGBM] [Info] Number of data points in the train set: 3179, number of used features: 116\n",
      "[LightGBM] [Info] Start training from score 102.463982\n",
      "üìä LightGBM Model Evaluation:\n",
      "‚û°Ô∏è MAE:  20.92\n",
      "‚û°Ô∏è MAPE: 41.63%\n",
      "‚û°Ô∏è RMSE: 30.53\n",
      "‚û°Ô∏è R¬≤:   0.88\n",
      "\n",
      "üèÜ Top 5 Feature Importances:\n",
      "           feature  importance\n",
      "0     target_lag_1         185\n",
      "3     target_lag_4         140\n",
      "113    day_of_week          90\n",
      "1     target_lag_2          68\n",
      "27   target_lag_28          54\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class LightGBMRegressorModel:\n",
    "    \"\"\"\n",
    "    A wrapper around LightGBM Regressor for consistent interface.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = lgb.LGBMRegressor(random_state=42, **kwargs)\n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series):\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test: pd.DataFrame) -> np.ndarray:\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def feature_importance(self, feature_names: list) -> pd.DataFrame:\n",
    "        return pd.DataFrame({\n",
    "            \"feature\": feature_names,\n",
    "            \"importance\": self.model.feature_importances_\n",
    "        }).sort_values(by=\"importance\", ascending=False)\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load transformed data\n",
    "df = pd.read_parquet(\"transformeddata2024.parquet\")\n",
    "\n",
    "# Define features and target\n",
    "features = [col for col in df.columns if col not in ['pickup_hour', 'target', 'location_id']]\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# Train/test split\n",
    "split_idx = int(0.8 * len(df))\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "# Train LightGBM model\n",
    "lgb_model = LightGBMRegressorModel()\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "print(\"üìä LightGBM Model Evaluation:\")\n",
    "print(f\"‚û°Ô∏è MAE:  {mae:.2f}\")\n",
    "print(f\"‚û°Ô∏è MAPE: {mape:.2f}%\")\n",
    "print(f\"‚û°Ô∏è RMSE: {rmse:.2f}\")\n",
    "print(f\"‚û°Ô∏è R¬≤:   {r2:.2f}\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nüèÜ Top 5 Feature Importances:\")\n",
    "print(lgb_model.feature_importance(features).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e04230ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def set_mlflow_tracking():\n",
    "    \"\"\"\n",
    "    Set up MLflow tracking server credentials and URI.\n",
    "    \"\"\"\n",
    "    uri = os.environ[\"MLFLOW_TRACKING_URI\"]\n",
    "    print(uri)\n",
    "    mlflow.set_tracking_uri(uri)\n",
    "    logger.info(\"MLflow tracking URI and credentials set.\")\n",
    "\n",
    "    return mlflow\n",
    "\n",
    "\n",
    "def log_model_to_mlflow(\n",
    "     model,\n",
    "    input_data,\n",
    "    experiment_name,\n",
    "    metric_name=\"metric\",\n",
    "    model_name=None,\n",
    "    params=None,\n",
    "    mae=None,\n",
    "    mape=None,\n",
    "    rmse=None,\n",
    "    r2=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Log a trained model, parameters, and metrics to MLflow.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model object (e.g., sklearn model).\n",
    "    - input_data: Input data used for training (for signature inference).\n",
    "    - experiment_name: Name of the MLflow experiment.\n",
    "    - metric_name: Name of the metric to log (e.g., \"RMSE\", \"accuracy\").\n",
    "    - model_name: Optional name for the registered model.\n",
    "    - params: Optional dictionary of hyperparameters to log.\n",
    "    - score: Optional evaluation metric to log.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set the experiment\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        logger.info(f\"Experiment set to: {experiment_name}\")\n",
    "\n",
    "        # Start an MLflow run\n",
    "        with mlflow.start_run():\n",
    "            # Log hyperparameters if provided\n",
    "            if params:\n",
    "                mlflow.log_params(params)\n",
    "                logger.info(f\"Logged parameters: {params}\")\n",
    "\n",
    "            # Log metrics if provided\n",
    "            if mae is not None:\n",
    "                mlflow.log_metric(metric_name, mae)\n",
    "                mlflow.log_metric(\"mape\", mape)\n",
    "                mlflow.log_metric(\"rmse\", rmse)\n",
    "                mlflow.log_metric(\"r2\", r2)\n",
    "                logger.info(f\"Logged {metric_name}: {mae}\")\n",
    "\n",
    "            # Infer the model signature\n",
    "            signature = infer_signature(input_data, model.predict(input_data))\n",
    "            logger.info(\"Model signature inferred.\")\n",
    "\n",
    "            # Determine the model name\n",
    "            if not model_name:\n",
    "                model_name = model.__class__.__name__\n",
    "\n",
    "            # Log the model\n",
    "            model_info = mlflow.sklearn.log_model(\n",
    "                sk_model=model,\n",
    "                artifact_path=\"model_artifact\",\n",
    "                signature=signature,\n",
    "                input_example=input_data,\n",
    "                registered_model_name=model_name,\n",
    "            )\n",
    "            logger.info(f\"Model logged with name: {model_name}\")\n",
    "            return model_info\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while logging to MLflow: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a42ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:MLflow tracking URI and credentials set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dagshub.com/jaathavan18/citi_bike_pred.mlflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/11 11:56:08 INFO mlflow.tracking.fluent: Experiment with name 'LightGbmWithTunedModel' does not exist. Creating a new experiment.\n",
      "INFO:__main__:Experiment set to: LightGbmWithTunedModel\n",
      "INFO:__main__:Logged mean_absolute_error: 20.92107717228034\n",
      "c:\\Users\\Jaath\\anaconda3\\envs\\citienv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "INFO:__main__:Model signature inferred.\n",
      "c:\\Users\\Jaath\\anaconda3\\envs\\citienv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 2335.92it/s]\n",
      "2025/05/11 11:56:13 INFO mlflow.models.model: Found the following environment variables used during model inference: [HOPSWORKS_API_KEY]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "Successfully registered model 'LightGBMRegressorModel'.\n",
      "2025/05/11 11:56:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LightGBMRegressorModel, version 1\n",
      "Created version '1' of model 'LightGBMRegressorModel'.\n",
      "INFO:__main__:Model logged with name: LightGBMRegressorModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run clumsy-skink-216 at: https://dagshub.com/jaathavan18/citi_bike_pred.mlflow/#/experiments/10/runs/3676301311424e5a802cbb0e70e89677\n",
      "üß™ View experiment at: https://dagshub.com/jaathavan18/citi_bike_pred.mlflow/#/experiments/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x1bdcfd7d190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "mlflow = set_mlflow_tracking()\n",
    "log_model_to_mlflow(model=lgb_model,\n",
    "    input_data=X_test,\n",
    "    experiment_name=\"LightGbmWithTunedModel\",\n",
    "    metric_name=\"mean_absolute_error\",\n",
    "    mae=mae,      \n",
    "    mape=mape,\n",
    "    rmse=rmse,\n",
    "    r2=r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
